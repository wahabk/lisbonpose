{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lisbonpose.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNseeu1GEdq0iRjwko4WOoI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wahabk/lisbonpose/blob/master/Lisbonpose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Alphapose with Lisbonpose\n",
        "\n",
        "First lets install alphhapose\n",
        "\n",
        "*note make sure you have GPU activated in Runtime > Change runtime\n"
      ],
      "metadata": {
        "id": "E89vyTf4Hn8F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4alfTMkHeIi"
      },
      "outputs": [],
      "source": [
        "!pip install -U torch==1.4 torchvision==0.5 -f https://download.pytorch.org/whl/cu101/torch_stable.html\n",
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "git_repo_url = 'https://github.com/MVIG-SJTU/AlphaPose.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # clone and install dependencies\n",
        "  !git clone -q {git_repo_url}\n",
        "  !pip install -q youtube-dl cython gdown\n",
        "  !pip install -q -U PyYAML\n",
        "  !apt-get install -y -q libyaml-dev\n",
        "  !cd {project_name} && git checkout 7be9809 && python setup.py build develop --user\n",
        "  \n",
        "import sys\n",
        "sys.path.append(project_name)\n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "plt.rcParams[\"axes.grid\"] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download pretrained models\n",
        "\n",
        "This will download a specified model from the alphapose github"
      ],
      "metadata": {
        "id": "qjYLuc_HLf7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_pretrained_model_path = join(project_name, 'detector/yolo/data/yolov3-spp.weights')\n",
        "if not exists(yolo_pretrained_model_path):\n",
        "  # download the YOLO weights\n",
        "  !mkdir -p {project_name}/detector/yolo/data\n",
        "  !gdown -O {yolo_pretrained_model_path} https://drive.google.com/uc?id=1D47msNOOiJKvPOXlnpyzdKA3k6E97NTC\n",
        "\n",
        "#tracker_pretrained_model_path = join(project_name, 'detector/tracker/data/jde.1088x608.uncertainty.pt')\n",
        "#if not exists(tracker_pretrained_model_path):\n",
        "#  # tracker weights\n",
        "#  !mkdir -p {project_name}/detector/tracker/data\n",
        "#  !gdown -O {tracker_pretrained_model_path} https://drive.google.com/uc?id=1nlnuYfGNuHWZztQHXwVZSL_FvfE551pA\n",
        "\n",
        "# ResNet152 backbone 73.3 AP\n",
        "pretrained_model_path = join(project_name, 'pretrained_models/fast_421_res152_256x192.pth')\n",
        "pretrained_model_config_path = join(project_name, 'configs/coco/resnet/256x192_res152_lr1e-3_1x-duc.yaml')\n",
        "if not exists(pretrained_model_path):\n",
        "  # download the pretrained model\n",
        "  !gdown -O {pretrained_model_path} https://drive.google.com/uc?id=1kfyedqyn8exjbbNmYq8XGd2EooQjPtF9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8i0wjxILnAv",
        "outputId": "d8f30f1f-4593-406f-bc5e-0487726ff609"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1D47msNOOiJKvPOXlnpyzdKA3k6E97NTC\n",
            "To: /content/AlphaPose/detector/yolo/data/yolov3-spp.weights\n",
            "100% 252M/252M [00:01<00:00, 170MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kfyedqyn8exjbbNmYq8XGd2EooQjPtF9\n",
            "To: /content/AlphaPose/pretrained_models/fast_421_res152_256x192.pth\n",
            "100% 334M/334M [00:03<00:00, 110MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now test shell and execute alphapose on video\n",
        "\n",
        "run ls and pwd\n",
        "\n",
        "download video from google drive\n",
        "\n",
        "then run alphapose"
      ],
      "metadata": {
        "id": "yhLpMj4PL50P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krInm3LdOCyC",
        "outputId": "fdddfe6a-5941-4379-8b0a-593dd04f8de8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = '/content/drive/MyDrive/PhD/output.mp4'\n",
        "\n",
        "!cd {project_name} && python3 scripts/demo_inference.py --sp --video {video_path} --outdir ../ --save_video --checkpoint ../{pretrained_model_path} --cfg ../{pretrained_model_config_path}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6_TCPp-SCnT",
        "outputId": "e6f82771-9fff-4bc5-ea0e-95fc2df744d7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load SE Resnet...\n",
            "Loading YOLO model..\n",
            "Network successfully loaded\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n",
            "100% 230M/230M [00:08<00:00, 28.9MB/s]\n",
            "Loading pose model from ../AlphaPose/pretrained_models/fast_421_res152_256x192.pth...\n",
            "===========================> This video get 480 frames in total.\n",
            "Could not find encoder for codec id 27: Encoder not found\n",
            "  0% 0/510 [00:00<?, ?it/s]Try to use other video encoders...\n",
            " 94% 480/510 [01:18<00:04,  6.10it/s]\n",
            "===========================> Finish Model Running.\n",
            "===========================> Rendering remaining images in the queue...\n",
            "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n",
            "===========================> Rendering remaining 195 images in the queue...\n",
            "===========================> Rendering remaining 185 images in the queue...\n",
            "===========================> Rendering remaining 175 images in the queue...\n",
            "===========================> Rendering remaining 165 images in the queue...\n",
            "===========================> Rendering remaining 155 images in the queue...\n",
            "===========================> Rendering remaining 145 images in the queue...\n",
            "===========================> Rendering remaining 134 images in the queue...\n",
            "===========================> Rendering remaining 124 images in the queue...\n",
            "===========================> Rendering remaining 114 images in the queue...\n",
            "===========================> Rendering remaining 104 images in the queue...\n",
            "===========================> Rendering remaining 94 images in the queue...\n",
            "===========================> Rendering remaining 84 images in the queue...\n",
            "===========================> Rendering remaining 74 images in the queue...\n",
            "===========================> Rendering remaining 63 images in the queue...\n",
            "===========================> Rendering remaining 53 images in the queue...\n",
            "===========================> Rendering remaining 43 images in the queue...\n",
            "===========================> Rendering remaining 33 images in the queue...\n",
            "===========================> Rendering remaining 23 images in the queue...\n",
            "===========================> Rendering remaining 13 images in the queue...\n",
            "===========================> Rendering remaining 3 images in the queue...\n",
            "===========================> Rendering remaining 0 images in the queue...\n",
            "Results have been written to json.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Done! \n",
        "\n",
        "You will now see `python AlphaPose_output.mp4 ` on the left hand side"
      ],
      "metadata": {
        "id": "92_ZqZ4pnIMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DL_KsdqTjfs",
        "outputId": "d9177c3f-76b7-44ce-dd96-77e174fb42e7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlphaPose  AlphaPose_output.mp4  alphapose-results.json  drive\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vysUuHtoTbib"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}